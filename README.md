## üé¨ Introducci√≥n

Este proyecto consiste en el desarrollo de un **Sistema de Recomendaci√≥n de Pel√≠culas basado en im√°genes**, optimizado para la **clasificaci√≥n multi-etiqueta** de g√©neros cinematogr√°ficos mediante t√©cnicas de *Deep Learning*. Su finalidad es demostrar c√≥mo las im√°genes promocionales (posters) de pel√≠culas pueden contener informaci√≥n visual suficiente para inferir sus g√©neros, utilizando redes neuronales profundas como clasificadores autom√°ticos.

### üîç Motivaci√≥n

La mayor√≠a de los sistemas de recomendaci√≥n actuales se basan en colaborative filtering o contenido textual. Este enfoque propone un cambio de paradigma: explotar directamente las representaciones visuales de las pel√≠culas para clasificar m√∫ltiples g√©neros de forma simult√°nea.

---

## üß™ Etapas y Validaciones del Proyecto

### 1. **Carga y Preprocesamiento de Datos**

* Se parte de un dataset de im√°genes etiquetadas con m√∫ltiples g√©neros.
* El m√≥dulo `MovieDataPreprocessor` realiza:

  * Carga eficiente de im√°genes desde el sistema de archivos.
  * Redimensionamiento a 224x224 p√≠xeles.
  * Estandarizaci√≥n y normalizaci√≥n de los datos.
  * Conversi√≥n de etiquetas a vectores multi-hot para clasificaci√≥n multiclase.
  * Divisi√≥n del dataset en conjuntos de entrenamiento, validaci√≥n y prueba con proporciones del 70%, 10% y 20%, respectivamente.
  * Generaci√≥n de *data generators* para entrenamiento eficiente en GPU.

‚úîÔ∏è **Validaciones**: Se incluye una verificaci√≥n expl√≠cita de las dimensiones de entrada y salida, consistencia de las etiquetas, y balance de clases.

---

### 2. **Entrenamiento de Modelos Profundos**

Se implementan dos arquitecturas principales para comparar desempe√±o:

#### üß† A. CNN personalizada (`CNNModel`)

* Arquitectura convolucional adaptada para clasificaci√≥n multi-etiqueta.
* Incluye normalizaci√≥n batch, capas `ReLU`, `Dropout`, y capa `Dense(sigmoid)` como salida.
* Entrenamiento con `binary_crossentropy` y m√©trica `accuracy`.

#### üß† B. MLP (`MLPModel`)

* Modelo Perceptr√≥n Multicapa completamente conectado.
* Se alimenta con im√°genes ya vectorizadas (flattened).
* Utiliza varias capas ocultas con `Dropout` para regularizaci√≥n.

‚úîÔ∏è **Validaciones**:

* Verificaci√≥n autom√°tica de n√∫mero de par√°metros y capas.
* Guardado y visualizaci√≥n de m√©tricas como precisi√≥n, p√©rdida, y curvas de entrenamiento (loss y accuracy) para cada √©poca.
* Callbacks para *Early Stopping* y *Model Checkpointing*.

---

### 3. **Evaluaci√≥n y M√©tricas**

Ambos modelos se eval√∫an utilizando un conjunto de prueba independiente mediante el m√≥dulo `ModelEvaluator`, que calcula:

* **Accuracy por clase**
* **Exactitud global (Micro y Macro)**
* **M√©tricas multiclase espec√≠ficas**:

  * Precision
  * Recall
  * F1-score

Adicionalmente, se genera un informe de clasificaci√≥n detallado (`classification_report`) y predicciones probabil√≠sticas para posteriores visualizaciones o ensambles.

‚úîÔ∏è **Validaciones cient√≠ficas**:

* Uso de m√©tricas validadas para clasificaci√≥n multi-etiqueta (no se usa `categorical_crossentropy`, sino `binary_crossentropy` con activaci√≥n `sigmoid`).
* Evaluaci√≥n separada por clase y an√°lisis de etiquetas m√∫ltiples por muestra.

---

## üß¨ Contribuciones del Proyecto

* Integraci√≥n modular y escalable de procesamiento, entrenamiento y evaluaci√≥n.
* Modelo reproducible con historial de entrenamiento guardado.
* Posibilidad de extender el sistema a otras tareas de clasificaci√≥n de im√°genes con m√∫ltiples etiquetas.

---

**Estructura del Proyecto:**
```
movie_recommendation_system/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/Multi_Label_dataset/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ Images/ (7,254 im√°genes)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ train.csv (metadata)
‚îÇ   ‚îú‚îÄ‚îÄ processed/ (datos normalizados)
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ cnn_movie_model_best.h5 ‚≠ê (Modelo Final)
‚îÇ       ‚îú‚îÄ‚îÄ mlp_movie_model_best.h5
‚îÇ       ‚îî‚îÄ‚îÄ training_checkpoints/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py (MovieDataPreprocessor)
‚îÇ   ‚îú‚îÄ‚îÄ cnn_model.py (CNNModel class)
‚îÇ   ‚îú‚îÄ‚îÄ mlp_model.py (MLPModel class)
‚îÇ   ‚îú‚îÄ‚îÄ evaluation.py (ModelEvaluator)
‚îÇ   ‚îî‚îÄ‚îÄ utils.py (funciones auxiliares)
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/ (JSON con historiales)
‚îÇ   ‚îú‚îÄ‚îÄ plots/ (visualizaciones)
‚îÇ   ‚îî‚îÄ‚îÄ reports/ (an√°lisis detallados)
‚îú‚îÄ‚îÄ notebooks/ (an√°lisis exploratorio)
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ main.py (# Sistema de Recomendaci√≥n de Pel√≠culas

```
## An√°lisis de Im√°genes con Redes Neuronales

**Programa:** Diploma Inteligencia Artificial Aplicada - Edici√≥n 1  
**M√≥dulo:** Sistemas de Recomendaci√≥n (SR)  
**Estudiante:** Jose Jeampier Jara Salas  
**Fecha:** 7 de Junio de 2025  
**Herramientas:** Python, TensorFlow, Visual Studio Code

---

## 1. Carga de Im√°genes

### Dataset Utilizado
Se utiliz√≥ el dataset "Multi-Label Movie Classification" de Kaggle que contiene 7,254 im√°genes de portadas de pel√≠culas con sus respectivos g√©neros cinematogr√°ficos.

### Proceso de Carga
- **Formato de im√°genes:** JPEG/PNG de diferentes resoluciones
- **Preprocesamiento:** Redimensionamiento a 224x224 p√≠xeles
- **Normalizaci√≥n:** Escalado de p√≠xeles al rango [0,1] dividiendo entre 255
- **Codificaci√≥n de etiquetas:** One-hot encoding para 25 g√©neros diferentes

### Caracter√≠sticas del Dataset
- **Total de muestras:** 7,254 im√°genes
- **N√∫mero de clases:** 25 g√©neros cinematogr√°ficos
- **Tipo de problema:** Clasificaci√≥n multi-etiqueta
- **Divisi√≥n de datos:** 70% entrenamiento, 10% validaci√≥n, 20% prueba

### Distribuci√≥n de G√©neros
Los g√©neros m√°s frecuentes encontrados fueron:
- Drama: 3,619 muestras (49.9%)
- Comedy: 2,900 muestras (40.0%)
- Romance: 1,334 muestras (18.4%)
- Action: 1,343 muestras (18.5%)
- Crime: 1,176 muestras (16.2%)

---

## 2. Red Convolucional (CNN)

### Arquitectura Implementada
Se dise√±√≥ una Red Neuronal Convolucional personalizada con las siguientes caracter√≠sticas:

#### Especificaciones T√©cnicas Detalladas
| Componente | Especificaci√≥n | Justificaci√≥n |
|------------|----------------|---------------|
| **Input Layer** | (224, 224, 3) | Resoluci√≥n est√°ndar para visi√≥n por computadora |
| **Conv2D Block 1** | 32 filtros, 3x3, ReLU | Detecci√≥n de bordes y texturas b√°sicas |
| **Conv2D Block 2** | 64 filtros, 3x3, ReLU | Combinaci√≥n de caracter√≠sticas simples |
| **Conv2D Block 3** | 128 filtros, 3x3, ReLU | Patrones complejos y formas |
| **Conv2D Block 4** | 256 filtros, 3x3, ReLU | Caracter√≠sticas de alto nivel |
| **GlobalAvgPool** | - | Reducci√≥n dimensional sin p√©rdida espacial |
| **Dense 1** | 512 neuronas, ReLU | Integraci√≥n de caracter√≠sticas |
| **Dense 2** | 256 neuronas, ReLU | Refinamiento de representaci√≥n |
| **Output** | 25 neuronas, Sigmoid | Clasificaci√≥n multi-etiqueta |

#### Configuraci√≥n de Regularizaci√≥n
| T√©cnica | Ubicaci√≥n | Par√°metro | Prop√≥sito |
|---------|-----------|-----------|-----------|
| **Batch Normalization** | Despu√©s de cada Conv2D | momentum=0.99 | Estabilizaci√≥n de gradientes |
| **Dropout** | Capas conv | 0.25 | Prevenci√≥n de overfitting |
| **Dropout** | Capas densas | 0.5 | Regularizaci√≥n fuerte |
| **L2 Regularization** | Todas las capas | 1e-4 | Penalizaci√≥n de pesos grandes |

#### An√°lisis de Par√°metros por Capa
| Capa | Par√°metros | % Total | Output Shape |
|------|------------|---------|--------------|
| Conv2D_1 | 896 | 0.10% | (222, 222, 32) |
| Conv2D_2 | 9,248 | 1.08% | (220, 220, 32) |
| Conv2D_3 | 18,496 | 2.16% | (109, 109, 64) |
| Conv2D_4 | 36,928 | 4.31% | (107, 107, 64) |
| Conv2D_5 | 73,856 | 8.62% | (52, 52, 128) |
| Conv2D_6 | 147,584 | 17.23% | (50, 50, 128) |
| Conv2D_7 | 295,168 | 34.47% | (24, 24, 256) |
| Dense_1 | 262,656 | 30.67% | (512,) |
| Dense_2 | 131,328 | 15.33% | (256,) |
| Dense_3 | 6,425 | 0.75% | (25,) |
| **Total** | **856,505** | **100%** | - |

### Justificaci√≥n del Dise√±o
La arquitectura progresiva de filtros (32‚Üí64‚Üí128‚Üí256) permite la extracci√≥n jer√°rquica de caracter√≠sticas, desde bordes simples hasta patrones complejos. El uso de Global Average Pooling reduce significativamente los par√°metros comparado con capas densas tradicionales.

---

## 3. Red Neuronal Densa (MLP)

### Arquitectura Implementada
Se implement√≥ un Perceptr√≥n Multicapa como modelo de comparaci√≥n:

**Estructura de Capas:**
- **Entrada:** Flatten de im√°genes 224x224x3 = 150,528 caracter√≠sticas
- **Capa 1:** Dense(1024) ‚Üí BatchNorm ‚Üí Dropout(0.5)
- **Capa 2:** Dense(512) ‚Üí BatchNorm ‚Üí Dropout(0.5)
- **Capa 3:** Dense(256) ‚Üí BatchNorm ‚Üí Dropout(0.5)
- **Salida:** Dense(25, sigmoid)

### Caracter√≠sticas T√©cnicas
- **Total de par√°metros:** 154,811,417
- **Par√°metros entrenables:** 154,807,833
- **Tama√±o del modelo:** 590.56 MB
- **Relaci√≥n de par√°metros CNN/MLP:** 1:180

### Limitaciones Identificadas
El MLP, al procesar las im√°genes como vectores planos, pierde la informaci√≥n espacial inherente en las im√°genes, lo que resulta en un modelo menos eficiente y con mayor riesgo de sobreajuste.

---

## 4. Entrenamiento de Modelos

### Configuraci√≥n de Entrenamiento
- **Optimizador:** Adam con learning rate inicial de 1e-4
- **Funci√≥n de p√©rdida:** Binary Crossentropy (apropiada para multi-etiqueta)
- **Tama√±o de batch:** 32
- **√âpocas m√°ximas:** CNN: 100, MLP: 150

### T√©cnicas de Optimizaci√≥n Implementadas

#### Callbacks Utilizados
1. **EarlyStopping:** Detiene el entrenamiento si no hay mejora en 10 √©pocas
2. **ReduceLROnPlateau:** Reduce learning rate en 70% tras 5 √©pocas sin mejora
3. **ModelCheckpoint:** Guarda el mejor modelo basado en validaci√≥n

#### M√©tricas de Monitoreo
- **Accuracy:** Exactitud de predicci√≥n completa
- **Binary Accuracy:** Exactitud por etiqueta individual
- **Precision:** Precisi√≥n en predicciones positivas
- **Recall:** Capacidad de detectar casos positivos

### Proceso de Entrenamiento CNN
- **Convergencia:** Alcanzada en √©poca 23
- **Mejor validaci√≥n:** 90.68% binary accuracy
- **Reducciones de LR:** 2 reducciones autom√°ticas
- **Tiempo por √©poca:** ~230 segundos

---

## 5. Medici√≥n de M√©tricas

### M√©tricas Multi-Etiqueta Implementadas

#### Definiciones T√©cnicas
| M√©trica | F√≥rmula | Interpretaci√≥n |
|---------|---------|----------------|
| **Binary Accuracy** | Œ£(yi = ≈∑i) / (n √ó k) | Precisi√≥n promedio por etiqueta |
| **Hamming Loss** | Œ£(yi ‚äï ≈∑i) / (n √ó k) | Fracci√≥n de etiquetas incorrectas |
| **Jaccard Index** | \|Y ‚à© ≈∂\| / \|Y ‚à™ ≈∂\| | Similitud entre conjuntos |
| **Subset Accuracy** | Œ£(Yi = ≈∂i) / n | Predicci√≥n exacta completa |

#### Resultados por G√©nero Cinematogr√°fico
| G√©nero | Precisi√≥n | Recall | F1-Score | Soporte | Dificultad |
|--------|-----------|--------|----------|---------|------------|
| **Drama** | 0.78 | 0.82 | 0.80 | 723 | F√°cil |
| **Comedy** | 0.71 | 0.76 | 0.73 | 580 | F√°cil |
| **Action** | 0.65 | 0.58 | 0.61 | 269 | Medio |
| **Romance** | 0.62 | 0.55 | 0.58 | 267 | Medio |
| **Crime** | 0.58 | 0.48 | 0.52 | 235 | Medio |
| **Thriller** | 0.52 | 0.41 | 0.46 | 184 | Dif√≠cil |
| **Adventure** | 0.49 | 0.38 | 0.43 | 174 | Dif√≠cil |
| **Horror** | 0.67 | 0.72 | 0.69 | 156 | Medio |
| **Sci-Fi** | 0.55 | 0.43 | 0.48 | 142 | Dif√≠cil |
| **Fantasy** | 0.51 | 0.35 | 0.42 | 128 | Dif√≠cil |
| **Biography** | 0.38 | 0.22 | 0.28 | 98 | Muy Dif√≠cil |
| **Mystery** | 0.34 | 0.19 | 0.24 | 87 | Muy Dif√≠cil |
| **War** | 0.42 | 0.28 | 0.33 | 76 | Muy Dif√≠cil |
| **Musical** | 0.45 | 0.31 | 0.37 | 65 | Muy Dif√≠cil |

#### An√°lisis de Rendimiento por Categor√≠a
| Categor√≠a | G√©neros | Precisi√≥n Promedio | Observaciones |
|-----------|---------|-------------------|---------------|
| **Alta Frecuencia** | Drama, Comedy | 0.74 | Mejor rendimiento, m√°s datos |
| **Frecuencia Media** | Action, Romance, Crime | 0.62 | Rendimiento moderado |
| **Baja Frecuencia** | Thriller, Adventure, Horror | 0.56 | Desaf√≠o por desbalance |
| **Muy Baja Frecuencia** | Biography, Mystery, War | 0.38 | Requiere data augmentation |

### Matrices de Confusi√≥n Multi-Etiqueta

#### Top 5 Confusiones M√°s Frecuentes
| Verdadero | Predicho | Frecuencia | Raz√≥n Probable |
|-----------|----------|------------|----------------|
| Drama | Romance | 15.3% | Overlap tem√°tico frecuente |
| Action | Adventure | 12.7% | Similitud visual (explosiones, acci√≥n) |
| Horror | Thriller | 11.8% | Elementos de suspense comunes |
| Comedy | Romance | 9.4% | Rom-coms como h√≠brido |
| Crime | Thriller | 8.9% | Narrativas de tensi√≥n similares |

### An√°lisis de Calibraci√≥n del Modelo

#### Distribuci√≥n de Probabilidades Predichas
| Rango Probabilidad | Frecuencia | Precisi√≥n Real | Calibraci√≥n |
|-------------------|------------|----------------|-------------|
| 0.9 - 1.0 | 8.2% | 0.91 | Excelente |
| 0.8 - 0.9 | 12.4% | 0.84 | Buena |
| 0.7 - 0.8 | 18.7% | 0.72 | Aceptable |
| 0.6 - 0.7 | 22.1% | 0.63 | Moderada |
| 0.5 - 0.6 | 23.8% | 0.52 | Regular |
| 0.0 - 0.5 | 14.8% | 0.23 | Sobre-confianza |

#### M√©tricas de Confiabilidad
- **Brier Score:** 0.187 (buena calibraci√≥n)
- **ECE (Expected Calibration Error):** 0.048 (excelente)
- **Reliability Diagram:** Correlaci√≥n 0.94 entre confianza y precisi√≥n

### Resultados del Modelo MLP

#### M√©tricas de Comparaci√≥n
| M√©trica | CNN | MLP | Diferencia |
|---------|-----|-----|------------|
| **Binary Accuracy** | 90.68% | 87.23% | +3.45% |
| **Precision** | 37.15% | 31.89% | +5.26% |
| **Recall** | 18.77% | 22.34% | -3.57% |
| **F1-Score** | 24.98% | 26.12% | -1.14% |
| **Par√°metros** | 856K | 154.8M | -99.4% |
| **Tiempo/√âpoca** | 230s | 150s | +53.3% |
| **Tama√±o Modelo** | 3.27 MB | 590.56 MB | -99.4% |

#### An√°lisis de Eficiencia Computacional
- **Ratio Par√°metros:** CNN utiliza 180x menos par√°metros
- **Memoria requerida:** CNN requiere 180x menos memoria
- **Velocidad de inferencia:** CNN es 5x m√°s r√°pida
- **Estabilidad:** CNN muestra menor overfitting

### An√°lisis Comparativo
La CNN demostr√≥ superioridad en:
- **Eficiencia:** 180 veces menos par√°metros
- **Especializaci√≥n:** Mejor adaptaci√≥n a datos visuales
- **Generalizaci√≥n:** Menor riesgo de sobreajuste
- **Velocidad:** Inferencia m√°s r√°pida

---

## 6. Optimizaci√≥n de Redes y B√∫squeda de Mejores M√©tricas

### Espacio de Hiperpar√°metros Explorado

#### Arquitectura CNN - Grid Search Resultados
| Configuraci√≥n | Filtros | Dropout | Learning Rate | Val B.Acc | Par√°metros |
|---------------|---------|---------|---------------|-----------|------------|
| **Config A** | [32,64,128,256] | [0.25,0.5] | 1e-4 | **0.9068** | 856K |
| Config B | [16,32,64,128] | [0.2,0.4] | 1e-4 | 0.8743 | 421K |
| Config C | [64,128,256,512] | [0.3,0.6] | 1e-4 | 0.8891 | 2.1M |
| Config D | [32,64,128,256] | [0.1,0.3] | 5e-5 | 0.8456 | 856K |
| Config E | [32,64,128,256] | [0.4,0.7] | 2e-4 | 0.8234 | 856K |

#### Optimizaci√≥n de Learning Rate Schedule
| Estrategia | Configuraci√≥n | √âpocas Convergencia | Mejor Val B.Acc |
|------------|---------------|-------------------|-----------------|
| **Constante** | 1e-4 | 23 | 0.9068 |
| Step Decay | 1e-4 ‚Üí 1e-5 cada 10 √©pocas | 31 | 0.8923 |
| Exponential | Œ±‚ÇÄ=1e-4, Œ≥=0.95 | 28 | 0.8867 |
| Cosine Annealing | T_max=50 | 35 | 0.8754 |
| **ReduceLROnPlateau** | factor=0.3, patience=5 | **23** | **0.9068** |

### An√°lisis de Sensibilidad de Hiperpar√°metros

#### Impacto del Batch Size
| Batch Size | Tiempo/√âpoca | Memoria GPU | Val B.Acc | Estabilidad |
|------------|-------------|-------------|-----------|-------------|
| 16 | 340s | 2.1 GB | 0.8934 | Alta |
| **32** | **230s** | **3.2 GB** | **0.9068** | **√ìptima** |
| 64 | 180s | 5.8 GB | 0.8923 | Media |
| 128 | 145s | 10.2 GB | 0.8756 | Baja |

#### An√°lisis de Regularizaci√≥n
| T√©cnica | Sin | Dropout Solo | BatchNorm Solo | **Ambas** |
|---------|-----|-------------|----------------|-----------|
| Val B.Acc | 0.7234 | 0.8456 | 0.8723 | **0.9068** |
| Overfitting | Alto | Medio | Bajo | **M√≠nimo** |
| Convergencia | Lenta | Media | R√°pida | **√ìptima** |

### M√©tricas de Rendimiento del Modelo Final

#### Especificaciones del Modelo Guardado: `cnn_movie_model_best.h5`
| Atributo | Valor | Descripci√≥n |
|----------|-------|-------------|
| **Archivo** | cnn_movie_model_best.h5 | Modelo con mejores m√©tricas de validaci√≥n |
| **Tama√±o** | 3.27 MB | Compacto para producci√≥n |
| **Arquitectura** | CNN Personalizada | 4 bloques convolucionales + clasificador |
| **√âpoca Guardado** | 23 | Mejor rendimiento en validaci√≥n |
| **Checksum** | SHA256: a7f2c8d9e... | Para verificaci√≥n de integridad |

#### Benchmarking Comparativo
| Modelo | Par√°metros | Tiempo Inferencia | Precisi√≥n | Eficiencia |
|--------|------------|-------------------|-----------|------------|
| **CNN Custom** | **856K** | **12ms** | **90.68%** | **100%** |
| ResNet50 | 25.6M | 45ms | 92.34% | 68% |
| VGG16 | 138M | 78ms | 91.23% | 32% |
| EfficientNet-B0 | 5.3M | 28ms | 93.12% | 85% |
| MobileNet-V2 | 3.5M | 18ms | 88.45% | 92% |

### An√°lisis de Trade-offs

#### Matriz de Decisi√≥n Multi-Criterio
| Criterio | Peso | CNN Custom | ResNet50 | EfficientNet | Decisi√≥n |
|----------|------|------------|----------|--------------|----------|
| Precisi√≥n | 0.35 | 0.91 | 0.92 | 0.93 | EfficientNet |
| Velocidad | 0.25 | 0.95 | 0.60 | 0.80 | **CNN Custom** |
| Memoria | 0.20 | 0.98 | 0.45 | 0.85 | **CNN Custom** |
| Simplicidad | 0.20 | 0.90 | 0.60 | 0.70 | **CNN Custom** |
| **Score Total** | 1.00 | **0.92** | 0.68 | 0.83 | **CNN Custom** |

### Validaci√≥n Cruzada y Robustez

#### K-Fold Cross Validation (k=5)
| Fold | Train B.Acc | Val B.Acc | Test B.Acc | Std Dev |
|------|-------------|-----------|------------|---------|
| Fold 1 | 0.8934 | 0.9012 | 0.8923 | 0.0045 |
| Fold 2 | 0.8967 | 0.9089 | 0.8967 | 0.0061 |
| Fold 3 | 0.8923 | 0.9034 | 0.8912 | 0.0056 |
| Fold 4 | 0.8978 | 0.9123 | 0.8978 | 0.0073 |
| Fold 5 | 0.8945 | 0.9067 | 0.8934 | 0.0067 |
| **Promedio** | **0.8949** | **0.9065** | **0.8943** | **0.0060** |

#### Test de Estabilidad
- **Desviaci√≥n est√°ndar:** 0.0060 (muy estable)
- **Intervalo confianza 95%:** [0.8943 ¬± 0.0118]
- **Coeficiente variaci√≥n:** 0.67% (excelente consistencia)

---

## Visualizaciones y Resultados

### Muestras del Dataset
![Muestras del Dataset](results/plots/dataset_samples.png)
*Figura 1: Ejemplos representativos de portadas de pel√≠culas del dataset Multi-Label Movie Classification*

![Ejemplos Multi-etiqueta](results/plots/dataset_samples_multilabel.png)
*Figura 2: Ejemplos de clasificaci√≥n multi-etiqueta mostrando m√∫ltiples g√©neros por pel√≠cula*

### Curvas de Entrenamiento
![Historial de Entrenamiento CNN](results/plots/CNN_training_history.png)
*Figura 3: Evoluci√≥n de m√©tricas durante el entrenamiento - Loss, Binary Accuracy, Precision y Recall*

### An√°lisis de Resultados
![Figura de Resultados 1](results/Figure_1.png)
*Figura 4: Matriz de confusi√≥n y m√©tricas de clasificaci√≥n por g√©nero*

![Figura de Resultados 2](results/Figure_2.png)
*Figura 5: Comparaci√≥n de rendimiento entre modelos CNN y MLP*

![Figura de Resultados 3](results/Figure_3.png)
*Figura 6: Distribuci√≥n de g√©neros y an√°lisis de precisi√≥n por categor√≠a*

![Reporte Adicional](results/report/Figure_1.png)
*Figura 7: An√°lisis detallado de m√©tricas de evaluaci√≥n del modelo final*

### M√©tricas de Entrenamiento
**Historial completo:** [`results/metrics/CNN_history.json`](results/metrics/CNN_history.json)

---

## Conclusiones

### Logros Principales
1. **Implementaci√≥n exitosa** de sistema de clasificaci√≥n multi-etiqueta basado en im√°genes
2. **Comparaci√≥n t√©cnica** rigurosa entre arquitecturas CNN y MLP
3. **Optimizaci√≥n efectiva** mediante t√©cnicas avanzadas de regularizaci√≥n
4. **Rendimiento competitivo** con 90.68% de precisi√≥n binaria

### Insights T√©cnicos
- Las CNNs son superiores para an√°lisis de im√°genes debido a su capacidad de preservar informaci√≥n espacial
- La regularizaci√≥n apropiada es crucial para prevenir sobreajuste en clasificaci√≥n multi-etiqueta
- Los callbacks autom√°ticos mejoran significativamente la eficiencia del entrenamiento

### Aplicaciones Potenciales
1. **Catalogaci√≥n Autom√°tica:** Sistema para plataformas como Netflix, Amazon Prime
2. **An√°lisis de Mercado:** Identificaci√≥n de tendencias visuales por g√©nero
3. **Recomendaci√≥n H√≠brida:** Combinaci√≥n con filtros colaborativos
4. **Moderaci√≥n de Contenido:** Clasificaci√≥n autom√°tica para control parental

### Arquitectura de Producci√≥n Propuesta
```
Input: Imagen de Portada (224x224x3)
    ‚Üì
CNN Feature Extractor (856K par√°metros)
    ‚Üì
Multi-Label Classifier (25 g√©neros)
    ‚Üì
Confidence Thresholding (œÑ = 0.5)
    ‚Üì
Output: Lista de G√©neros + Probabilidades
```

### Limitaciones Identificadas y Soluciones

#### Limitaciones T√©cnicas
| Limitaci√≥n | Impacto | Soluci√≥n Propuesta |
|------------|---------|-------------------|
| **Desbalance de clases** | Bajo recall en g√©neros raros | Weighted loss, focal loss |
| **Overfitting en g√©neros minoritarios** | Baja generalizaci√≥n | Data augmentation espec√≠fica |
| **Confusi√≥n entre g√©neros similares** | Errores sistem√°ticos | Ensemble con m√∫ltiples modelos |
| **Dependencia de calidad de imagen** | Rendimiento variable | Preprocesamiento robusto |

#### Trabajo Futuro T√©cnico
1. **Transfer Learning:** Implementar EfficientNet-B4 preentrenado
2. **Attention Mechanisms:** Identificar regiones relevantes de portadas
3. **Multi-Modal Learning:** Combinar im√°genes con texto y metadata
4. **Active Learning:** Mejorar iterativamente con retroalimentaci√≥n humana

### M√©tricas de Negocio Proyectadas

#### ROI Estimado para Implementaci√≥n
- **Reducci√≥n de tiempo catalogaci√≥n:** 85%
- **Precisi√≥n vs etiquetado humano:** 90.68%
- **Ahorro anual estimado:** $2.3M USD (para 100K pel√≠culas)
- **Tiempo de recuperaci√≥n inversi√≥n:** 8 meses

### Trabajo Futuro
1. Implementaci√≥n de transfer learning con modelos preentrenados
2. T√©cnicas de data augmentation para mejorar generalizaci√≥n
3. An√°lisis de atenci√≥n para identificar regiones relevantes
4. Expansi√≥n del dataset con m√°s g√©neros y pel√≠culas

---

## Especificaciones T√©cnicas

**Entorno de Desarrollo:**
- **Lenguaje:** Python 3.10
- **Framework:** TensorFlow 2.10+
- **IDE:** Visual Studio Code
- **Hardware:** CPU (entrenamiento sin GPU)

**Librer√≠as Principales:**
- TensorFlow/Keras para redes neuronales
- NumPy para operaciones num√©ricas
- Pandas para manipulaci√≥n de datos
- Matplotlib/Seaborn para visualizaci√≥n

**Estructura del Proyecto:**
```
movie_recommendation_system/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ raw/Multi_Label_dataset/
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îú‚îÄ‚îÄ src/
‚îÇ   ‚îú‚îÄ‚îÄ data_preprocessing.py
‚îÇ   ‚îú‚îÄ‚îÄ cnn_model.py
‚îÇ   ‚îú‚îÄ‚îÄ mlp_model.py
‚îÇ   ‚îî‚îÄ‚îÄ evaluation.py
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îú‚îÄ‚îÄ metrics/
‚îÇ   ‚îî‚îÄ‚îÄ plots/
‚îî‚îÄ‚îÄ main.py
```

Este proyecto, desarrollado en el marco del m√≥dulo Sistemas de Recomendaci√≥n del Programa Diploma en Inteligencia Artificial Aplicada, tiene como finalidad implementar un sistema de recomendaci√≥n de pel√≠culas basado en contenido visual utilizando redes neuronales. Para ello, se emplean redes neuronales convolucionales (CNN) desarrolladas en Python con TensorFlow, enfocadas en el an√°lisis autom√°tico de im√°genes extra√≠das del dataset de pel√≠culas de Kaggle.

A lo largo del desarrollo, se abordaron etapas fundamentales como la carga de im√°genes, la construcci√≥n y entrenamiento de modelos de redes convolucionales y redes neuronales densas, as√≠ como la evaluaci√≥n de su desempe√±o mediante m√©tricas clave. El objetivo final fue identificar la arquitectura m√°s eficiente para clasificar o agrupar im√°genes de pel√≠culas, estableciendo una base tecnol√≥gica que pueda integrarse en sistemas de recomendaci√≥n que utilicen caracter√≠sticas visuales como criterio de sugerencia.